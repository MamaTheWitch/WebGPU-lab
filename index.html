<!DOCTYPE html>

<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width" />
  <title>WebGPU Life</title>
  <link rel="stylesheet" type="text/css" href="index.css" />
  <!-- <link rel="stylesheet" href="path/to/font-awesome/css/font-awesome.min.css"> -->
</head>

<body>
  <div id="title">
    <h1 class="title">YogaPlayBreak</h1>
  </div>

  <div class="container">
    <div>
      <div class="btn" id="counter">
        <p>5 turns left</p>
      </div>

      <div class="label">
        <p class="number">3 X</p>
        <img src="pose2.jpg" alt="pose" width="50" height="50" />
        <p class="number">= 3 €</p>
      </div>
      <div class="label">
        <p class="number">2 X</p>
        <img src="pose2.jpg" alt="pose" width="50" height="50" />
        <p class="number">= 2 €</p>
      </div>
    </div>

    <div class="canvas-div">
      <canvas width="512" height="512" id="imageGrid"></canvas>
    </div>
  </div>

  <script type="module">
    const canvas = document.querySelector("canvas");
    // Your WebGPU code will begin here!
    // This is the entry point for your WebGPU application.
    if (!navigator.gpu) {
      throw new Error("WebGPU not supported on this browser.");
    }

    const adapter = await navigator.gpu.requestAdapter();
    if (!adapter) {
      throw new Error("No appropriate GPUAdapter found.");
    }
    // Create the GPUDevice, which represents a connection to the GPU.
    const device = await adapter.requestDevice();

    const GRID_SIZE = 4; // any number in the power of 2
    const cellWidth = canvas.width / GRID_SIZE;
    const cellHeight = canvas.height / GRID_SIZE;
    // Create a uniform buffer that describes the grid:
    const uniformArray = new Float32Array([GRID_SIZE, GRID_SIZE]);
    const uniformBuffer = device.createBuffer({
      label: "Grid Uniforms",
      size: uniformArray.byteLength,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });
    device.queue.writeBuffer(uniformBuffer, 0, uniformArray);

    const cellStateArray = new Float32Array([
      0, 0, 0, 0,
      0, 0, 0, 0,
      0, 0, 0, 0,
      0, 0, 0, 0
    ]);
    const uniformBufferClick1 = device.createBuffer({
      label: "Grid Uniforms",
      size: cellStateArray.byteLength,
      usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
    });
    device.queue.writeBuffer(uniformBufferClick1, 0, uniformArray);

    // Create the GPUContext, which represents the GPU itself.
    const context = canvas.getContext("webgpu");
    const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
    context.configure({ device: device, format: canvasFormat });

    const vertices = new Float32Array([
      //   X,    Y,
      -0.8, -0.8, // Triangle 1 (Blue)
      0.8, -0.8,
      0.8, 0.8,

      -0.8, -0.8, // Triangle 2 (Red)
      0.8, 0.8,
      -0.8, 0.8,
    ]);

    const vertexBuffer = device.createBuffer({
      label: "Cell vertices",
      size: vertices.byteLength,
      usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
    });

    device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/0, vertices);
    console.log("4");
    const vertexBufferLayout = {
      arrayStride: 8,
      attributes: [{
        format: "float32x2",
        offset: 0,
        shaderLocation: 0, // Position, see vertex shader. 
        // This is an arbitrary number between 0 and 15 and must be unique 
        // for every attribute that you define. 
      }],
    };
    console.log("5");
    // Create an array representing the active state of each cell.


    // Create a storage buffer to hold the cell state.


    let textures = [];

    const pose1 = document.createElement("img");
    pose1.src = "pose1.jpg";
    await new Promise(resolve => { pose1.onload = resolve; });
    const pose1Texture = await webGPUTextureFromImageBitmapOrCanvas(device, pose1);
    textures.push(pose1Texture);

    const pose2 = document.createElement("img");
    pose2.src = "pose2.jpg";
    await new Promise(resolve => { pose2.onload = resolve; });
    const pose2Texture = await webGPUTextureFromImageBitmapOrCanvas(device, pose2);
    textures.push(pose2Texture);

    const pose3 = document.createElement("img");
    pose3.src = "pose3.jpg";
    await new Promise(resolve => { pose3.onload = resolve; });
    const pose3Texture = await webGPUTextureFromImageBitmapOrCanvas(device, pose3);
    textures.push(pose3Texture);

    const textureArray = [];
    for (let i = 0; i < textures.length; i++) {
      textureArray.push(
        device.createTexture({
          size: { width: textures[0].width, height: textures[0].height, depthOrArrayLayers: textures.length },
          format: 'rgba8unorm',
          usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,
        })
      );
    };

    var url = '';
    let textureIndex = 0;

    canvas.addEventListener('click', event => {
      const rect = canvas.getBoundingClientRect();
      const x = event.clientX - rect.left;
      const y = event.clientY - rect.top;

      const cellX = Math.floor(x / cellWidth);
      const cellY = Math.floor(y / cellHeight);

      const index = cellY * GRID_SIZE + cellX;
      cellStateArray[index] = 1;
      // Set the texture based on the cell state
      const url = (cellStateArray[index] === 0) ? 'button.jpg' : 'pose1.jpg';

      // Generate a random index for the texture array
      textureIndex = Math.floor(Math.random() * textures.length);

      // Update the bind group with the new texture
      //bindGroup = updateBindGroup(textureIndex);

      // Update the cell state buffer
      device.queue.writeBuffer(cellStateStorage, 0, cellStateArray);
      console.log(cellStateArray);
      console.log(cellStateStorage);
    });

    const cellShaderModule = device.createShaderModule({
      label: "Cell shader",
      code: `
              struct VertexInput {
                @location(0) pos: vec2f,
                @builtin(instance_index) instance: u32,
              };

              struct VertexOutput {
                @builtin(position) pos: vec4f,
                @location(0) cell: vec2f,
                @location(1) @interpolate(flat) instance: u32,
              };
              
              @group(0) @binding(0) var<uniform> grid: vec2f;
              @group(0) @binding(1) var sampler1: sampler;
              @group(0) @binding(2) var texture1: texture_2d<f32>;
              @group(0) @binding(3) var<uniform> cellState: f32;
              @group(0) @binding(4) var texture2: texture_2d<f32>;
              @group(0) @binding(5) var texture3: texture_2d<f32>;
              @group(0) @binding(6) var texture4: texture_2d<f32>;
              

              @vertex
              fn vertexMain(input: VertexInput) -> VertexOutput  {
                let i = f32(input.instance);
                let cell = vec2f(i % grid.x, floor(i / grid.x));
                //let state = f32(cellState[input.instance]);
                let cellOffset = cell / grid * 2;
                 let gridPos = (input.pos + 1) / grid - 1 + cellOffset;
                // New: Scale the position by the cell's active state.
                // let gridPos = (input.pos * state + 1) / grid - 1 + cellOffset;
                
                var output: VertexOutput;
                output.pos = vec4f(gridPos, 0, 1);
                output.cell = cell;
                output.cell = input.pos.xy;
                output.instance = input.instance;
                return output;
              };

              @fragment
              fn fragmentMain(input: VertexOutput) -> @location(0) vec4f {
                var c = input.cell *0.5 + 0.5;
                c.y = 1.0-c.y;
             //   let state = u32(cellState[input.instance]);
                var color = textureSample(texture1, sampler1, c);
                let color1 = textureSample(texture2, sampler1, c);
                let color2 = textureSample(texture3, sampler1, c);
                let color3 = textureSample(texture4, sampler1, c);
              
               // return vec4f((cellState[input.instance]),0.0,0.0, 1.0);
                // return vec4f(input.cell.x, input.cell.y, 0.0, 1.0);
                return vec4f(color.rgb, 1.0);
                
              };
        `
    });

    const sampler = device.createSampler({});


    async function webGPUTextureFromImageUrl(device, url) {
      const response = await fetch(url);
      const blob = await response.blob();
      const ImageBitmap = await createImageBitmap(blob);

      console.log("it works");
      return webGPUTextureFromImageBitmapOrCanvas(device, ImageBitmap);

    }
    // Defining this as a separate function because we'll be re-using it a lot.

    function webGPUTextureFromImageBitmapOrCanvas(device, source) {
      const textureDescriptor = {
        size: { width: source.width, height: source.height, depthOrArrayLayers: 1 },
        format: 'rgba8unorm',
        usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,
      };

      const texture = device.createTexture(textureDescriptor);

      device.queue.copyExternalImageToTexture(
        { source: source },
        { texture: texture },
        [source.width, source.height, 1]
      );

      return texture;
    };

    let bindGroupLayout = device.createBindGroupLayout({
      entries: [
        {
          binding: 0,
          visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.VERTEX,
          buffer: { type: 'uniform' },
        },
        {
          binding: 1,
          visibility: GPUShaderStage.FRAGMENT,
          sampler: { type: 'filtering' },
        },
        {
          binding: 2,
          visibility: GPUShaderStage.FRAGMENT,
          texture: { sampleType: 'float' },
        },
        {
          binding: 3,
          visibility: GPUShaderStage.FRAGMENT,
          buffer: { type: 'uniform' },
        },

        {
          binding: 4,
          visibility: GPUShaderStage.FRAGMENT,
          texture: { sampleType: 'float' },
        },

        {
          binding: 5,
          visibility: GPUShaderStage.FRAGMENT,
          texture: { sampleType: 'float' },
        },

        {
          binding: 6,
          visibility: GPUShaderStage.FRAGMENT,
          texture: { sampleType: 'float' },
        },

      ],
    });

    const imgElement = document.createElement("img");
    imgElement.src = "button.jpg";
    await new Promise((resolve) => {
      imgElement.onload = resolve;
    });
    const imageTexture = await webGPUTextureFromImageBitmapOrCanvas(
      device,
      imgElement
    );

    const bindGroup = device.createBindGroup({
      layout: bindGroupLayout,
      entries: [
        { binding: 0, resource: { buffer: uniformBuffer } },
        { binding: 1, resource: sampler },
        { binding: 2, resource: imageTexture.createView() },
        // { binding: 2, resource: textureArray.createView() },
        { binding: 3, resource: { buffer: uniformBufferClick1 } },
        { binding: 4, resource: textures[0].createView() },
        { binding: 5, resource: textures[1].createView() },
        { binding: 6, resource: textures[2].createView() },

      ],
    });

    const pipelineLayout = device.createPipelineLayout({
      bindGroupLayouts: [bindGroupLayout],
    });
    console.log("test");
    const cellPipeline = device.createRenderPipeline({
      label: "Cell pipeline",
      layout: pipelineLayout,
      vertex: {
        module: cellShaderModule,
        entryPoint: "vertexMain",
        buffers: [vertexBufferLayout]
      },
      fragment: {
        module: cellShaderModule,
        entryPoint: "fragmentMain",
        targets: [{
          format: canvasFormat
        }]
      }
    });
    console.log(cellPipeline);
    console.log("test");

    const encoder = device.createCommandEncoder();

    // Create a GPURenderPassEncoder to encode the drawing commands.
    const pass = encoder.beginRenderPass({
      colorAttachments: [
        {
          view: context.getCurrentTexture().createView(),
          loadOp: "clear",
          clearValue: [1, 1, 1, 0], // { r: 0, g: 0, b: 0.4, a: 1 }, #FEF7E6
          storeOp: "store",
        },
      ],
    });

    pass.setPipeline(cellPipeline);
    pass.setVertexBuffer(0, vertexBuffer); // 0 is the first element of the vertex buffer
    pass.setBindGroup(0, bindGroup);
    pass.draw(vertices.length / 2, GRID_SIZE * GRID_SIZE); // 6 vertices in 2 triangles

    pass.end();

    // Finish the command buffer and immediately submit it.
    device.queue.submit([encoder.finish()]);
    // After you submit the commands to the GPU, let JavaScript return control to the browser.
    // At that point, the browser sees that you've changed the current texture of the context
    // and updates the canvas to display that texture as an image.
    // If you want to update the canvas contents again after that,
    // you need to record and submit a new command buffer,
    // calling context.getCurrentTexture() again to get a new texture for a render pass.
  </script>
  <script src="counter.js"></script>
</body>

</html>