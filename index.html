<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <title>WebGPU Life</title>
    <link rel="stylesheet" type="text/css" href="index.css" />
    <link rel="stylesheet" href="path/to/font-awesome/css/font-awesome.min.css">
  </head>

  <body>
    <div id="title">
      <h1 class="title">YogaPlayBreak</h1>
    </div>

    <div class="container">
      <div>
        <div class="btn" id="counter"><p>5 turns left</p></div>

        <div class="label">
          <p class="number">3 X</p>
          <img src="pose2.jpg" alt="pose" width="50" height="50" />
          <p class="number">= 3 €</p>
        </div>
        <div class="label">
          <p class="number">2 X</p>
          <img src="pose2.jpg" alt="pose" width="50" height="50" />
          <p class="number">= 2 €</p>
        </div>
      </div>

      <div class="canvas-div">
        <canvas width="512" height="512" id="imageGrid"></canvas>
      </div>
    </div>

    <script type="module">
      const canvas = document.querySelector("canvas");
      // Your WebGPU code will begin here!
      // This is the entry point for your WebGPU application.
      if (!navigator.gpu) {
        throw new Error("WebGPU not supported on this browser.");
      }

      const adapter = await navigator.gpu.requestAdapter();
      if (!adapter) {
        throw new Error("No appropriate GPUAdapter found.");
      }
      // Create the GPUDevice, which represents a connection to the GPU.
      const device = await adapter.requestDevice();

      const GRID_SIZE = 4; // any number in the power of 2
      // const CELL_SIZE = 128;
      // Create a uniform buffer that describes the grid:
      const uniformArray = new Float32Array([GRID_SIZE, GRID_SIZE]);
      const uniformBuffer = device.createBuffer({
        label: "Grid Uniforms",
        size: uniformArray.byteLength,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
      });
      device.queue.writeBuffer(uniformBuffer, 0, uniformArray);

      // Create the GPUContext, which represents the GPU itself.
      const context = canvas.getContext("webgpu");
      const canvasFormat = navigator.gpu.getPreferredCanvasFormat();
      context.configure({ device: device, format: canvasFormat });

      const vertices = new Float32Array([
        //   X,    Y,
        -0.8,
        -0.8, // Triangle 1 (Blue)
        0.8,
        -0.8,
        0.8,
        0.8,

        -0.8,
        -0.8, // Triangle 2 (Red)
        0.8,
        0.8,
        -0.8,
        0.8,
      ]);

      const vertexBuffer = device.createBuffer({
        label: "Cell vertices",
        size: vertices.byteLength,
        usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
        // mappedAtCreation: true, // added by copilot
      });

      device.queue.writeBuffer(vertexBuffer, /*bufferOffset=*/ 0, vertices);

      const vertexBufferLayout = {
        arrayStride: 8,
        attributes: [
          {
            format: "float32x2",
            offset: 0,
            shaderLocation: 0, // Position, see vertex shader.
            // This is an arbitrary number between 0 and 15 and must be unique
            // for every attribute that you define.
          },
        ],
      };

      const cellShaderModule = device.createShaderModule({
        label: "Cell shader",
        code: `
              struct VertexInput {
                @location(0) pos: vec2f,
                @builtin(instance_index) instance: u32,
              };

              struct VertexOutput {
                @builtin(position) pos: vec4f,
                @location(0) cell: vec2f,
              };

              @group(0) @binding(0) var<uniform> grid: vec2f;
              @group(0) @binding(1) var sampler1: sampler;
              @group(0) @binding(2) var texture1: texture_2d<f32>;


              @vertex
              fn vertexMain(input: VertexInput) -> VertexOutput  {
                let i = f32(input.instance);
                let cell = vec2f(i % grid.x, floor(i / grid.x));
                let cellOffset = cell / grid * 2;
                let gridPos = (input.pos + 1) / grid - 1 + cellOffset;
                
                var output: VertexOutput;
                output.pos = vec4f(gridPos, 0, 1);
                output.cell = cell;
                output.cell = input.pos.xy;
                return output;
              };

              @fragment
              fn fragmentMain(input: VertexOutput) -> @location(0) vec4f {
                var c = input.cell *0.5 + 0.5;
                c.y = 1.0-c.y;
                let color = textureSample(texture1, sampler1, c);
               // return vec4f(input.cell.x, input.cell.y, 0.0, 1.0);
                return vec4f(color.rgb, 1.0);
                
              };
        `,
      });

      const sampler = device.createSampler({});
      const url = "button.jpg";

      async function webGPUTextureFromImageUrl(device, url) {
        const response = await fetch(url);
        const blob = await response.blob();
        const ImageBitmap = await createImageBitmap(blob);

        await new Promise((resolve) => {
          ImageBitmap.onload = resolve;
        });

        return webGPUTextureFromImageBitmapOrCanvas(device, ImageBitmap);
      }
      // Defining this as a separate function because we'll be re-using it a lot.

      function webGPUTextureFromImageBitmapOrCanvas(device, source) {
        const textureDescriptor = {
          size: {
            width: source.width,
            height: source.height,
            depthOrArrayLayers: 1,
          },
          format: "rgba8unorm",
          usage:
            GPUTextureUsage.TEXTURE_BINDING |
            GPUTextureUsage.COPY_DST |
            GPUTextureUsage.RENDER_ATTACHMENT,
        };

        const texture = device.createTexture(textureDescriptor);

        device.queue.copyExternalImageToTexture(
          { source: source },
          { texture: texture },
          [source.width, source.height, 1]
        );

        return texture;
      }

      let bindGroupLayout = device.createBindGroupLayout({
        entries: [
          {
            binding: 0,
            visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.VERTEX,
            buffer: { type: "uniform" },
          },
          {
            binding: 1,
            visibility: GPUShaderStage.FRAGMENT,
            sampler: { type: "filtering" },
          },
          {
            binding: 2,
            visibility: GPUShaderStage.FRAGMENT,
            texture: { sampleType: "float" },
          },
        ],
      });

      const imgElement = document.createElement("img");
      imgElement.src = "button.jpg";
      await new Promise((resolve) => {
        imgElement.onload = resolve;
      });
      const imageTexture = await webGPUTextureFromImageBitmapOrCanvas(
        device,
        imgElement
      );

      const bindGroup = device.createBindGroup({
        layout: bindGroupLayout,
        entries: [
          { binding: 0, resource: { buffer: uniformBuffer } },
          { binding: 1, resource: sampler },
          { binding: 2, resource: imageTexture.createView() },
        ],
      });

      const pipelineLayout = device.createPipelineLayout({
        bindGroupLayouts: [bindGroupLayout],
      });

      const cellPipeline = device.createRenderPipeline({
        label: "Cell pipeline",
        layout: pipelineLayout,
        vertex: {
          module: cellShaderModule,
          entryPoint: "vertexMain",
          buffers: [vertexBufferLayout],
        },
        fragment: {
          module: cellShaderModule,
          entryPoint: "fragmentMain",
          targets: [
            {
              format: canvasFormat,
            },
          ],
        },
      });

      const encoder = device.createCommandEncoder();

      // Create a GPURenderPassEncoder to encode the drawing commands.
      const pass = encoder.beginRenderPass({
        colorAttachments: [
          {
            view: context.getCurrentTexture().createView(),
            loadOp: "clear",
            clearValue: [1, 1, 1, 0], // { r: 0, g: 0, b: 0.4, a: 1 }, #FEF7E6
            storeOp: "store",
          },
        ],
      });

      pass.setPipeline(cellPipeline);
      pass.setVertexBuffer(0, vertexBuffer); // 0 is the first element of the vertex buffer
      pass.setBindGroup(0, bindGroup);
      pass.draw(vertices.length / 2, GRID_SIZE * GRID_SIZE); // 6 vertices in 2 triangles

      pass.end();

      // Finish the command buffer and immediately submit it.
      device.queue.submit([encoder.finish()]);
      // After you submit the commands to the GPU, let JavaScript return control to the browser.
      // At that point, the browser sees that you've changed the current texture of the context
      // and updates the canvas to display that texture as an image.
      // If you want to update the canvas contents again after that,
      // you need to record and submit a new command buffer,
      // calling context.getCurrentTexture() again to get a new texture for a render pass.
    </script>
    <script src="counter.js"></script>
  </body>
</html>
